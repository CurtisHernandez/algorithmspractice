{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Google Compute engine to run the Keras tutorial.  First, importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4             0.700         0.00            1.90      0.076   \n",
      "1               7.8             0.880         0.00            2.60      0.098   \n",
      "2               7.8             0.760         0.04            2.30      0.092   \n",
      "3              11.2             0.280         0.56            1.90      0.075   \n",
      "4               7.4             0.700         0.00            1.90      0.076   \n",
      "5               7.4             0.660         0.00            1.80      0.075   \n",
      "6               7.9             0.600         0.06            1.60      0.069   \n",
      "7               7.3             0.650         0.00            1.20      0.065   \n",
      "8               7.8             0.580         0.02            2.00      0.073   \n",
      "9               7.5             0.500         0.36            6.10      0.071   \n",
      "10              6.7             0.580         0.08            1.80      0.097   \n",
      "11              7.5             0.500         0.36            6.10      0.071   \n",
      "12              5.6             0.615         0.00            1.60      0.089   \n",
      "13              7.8             0.610         0.29            1.60      0.114   \n",
      "14              8.9             0.620         0.18            3.80      0.176   \n",
      "15              8.9             0.620         0.19            3.90      0.170   \n",
      "16              8.5             0.280         0.56            1.80      0.092   \n",
      "17              8.1             0.560         0.28            1.70      0.368   \n",
      "18              7.4             0.590         0.08            4.40      0.086   \n",
      "19              7.9             0.320         0.51            1.80      0.341   \n",
      "20              8.9             0.220         0.48            1.80      0.077   \n",
      "21              7.6             0.390         0.31            2.30      0.082   \n",
      "22              7.9             0.430         0.21            1.60      0.106   \n",
      "23              8.5             0.490         0.11            2.30      0.084   \n",
      "24              6.9             0.400         0.14            2.40      0.085   \n",
      "25              6.3             0.390         0.16            1.40      0.080   \n",
      "26              7.6             0.410         0.24            1.80      0.080   \n",
      "27              7.9             0.430         0.21            1.60      0.106   \n",
      "28              7.1             0.710         0.00            1.90      0.080   \n",
      "29              7.8             0.645         0.00            2.00      0.082   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "6467            5.8             0.230         0.31            4.50      0.046   \n",
      "6468            6.6             0.240         0.33           10.10      0.032   \n",
      "6469            6.1             0.320         0.28            6.60      0.021   \n",
      "6470            5.0             0.200         0.40            1.90      0.015   \n",
      "6471            6.0             0.420         0.41           12.40      0.032   \n",
      "6472            5.7             0.210         0.32            1.60      0.030   \n",
      "6473            5.6             0.200         0.36            2.50      0.048   \n",
      "6474            7.4             0.220         0.26            1.20      0.035   \n",
      "6475            6.2             0.380         0.42            2.50      0.038   \n",
      "6476            5.9             0.540         0.00            0.80      0.032   \n",
      "6477            6.2             0.530         0.02            0.90      0.035   \n",
      "6478            6.6             0.340         0.40            8.10      0.046   \n",
      "6479            6.6             0.340         0.40            8.10      0.046   \n",
      "6480            5.0             0.235         0.27           11.75      0.030   \n",
      "6481            5.5             0.320         0.13            1.30      0.037   \n",
      "6482            4.9             0.470         0.17            1.90      0.035   \n",
      "6483            6.5             0.330         0.38            8.30      0.048   \n",
      "6484            6.6             0.340         0.40            8.10      0.046   \n",
      "6485            6.2             0.210         0.28            5.70      0.028   \n",
      "6486            6.2             0.410         0.22            1.90      0.023   \n",
      "6487            6.8             0.220         0.36            1.20      0.052   \n",
      "6488            4.9             0.235         0.27           11.75      0.030   \n",
      "6489            6.1             0.340         0.29            2.20      0.036   \n",
      "6490            5.7             0.210         0.32            0.90      0.038   \n",
      "6491            6.5             0.230         0.38            1.30      0.032   \n",
      "6492            6.2             0.210         0.29            1.60      0.039   \n",
      "6493            6.6             0.320         0.36            8.00      0.047   \n",
      "6494            6.5             0.240         0.19            1.20      0.041   \n",
      "6495            5.5             0.290         0.30            1.10      0.022   \n",
      "6496            6.0             0.210         0.38            0.80      0.020   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "5                    13.0                  40.0  0.99780  3.51       0.56   \n",
      "6                    15.0                  59.0  0.99640  3.30       0.46   \n",
      "7                    15.0                  21.0  0.99460  3.39       0.47   \n",
      "8                     9.0                  18.0  0.99680  3.36       0.57   \n",
      "9                    17.0                 102.0  0.99780  3.35       0.80   \n",
      "10                   15.0                  65.0  0.99590  3.28       0.54   \n",
      "11                   17.0                 102.0  0.99780  3.35       0.80   \n",
      "12                   16.0                  59.0  0.99430  3.58       0.52   \n",
      "13                    9.0                  29.0  0.99740  3.26       1.56   \n",
      "14                   52.0                 145.0  0.99860  3.16       0.88   \n",
      "15                   51.0                 148.0  0.99860  3.17       0.93   \n",
      "16                   35.0                 103.0  0.99690  3.30       0.75   \n",
      "17                   16.0                  56.0  0.99680  3.11       1.28   \n",
      "18                    6.0                  29.0  0.99740  3.38       0.50   \n",
      "19                   17.0                  56.0  0.99690  3.04       1.08   \n",
      "20                   29.0                  60.0  0.99680  3.39       0.53   \n",
      "21                   23.0                  71.0  0.99820  3.52       0.65   \n",
      "22                   10.0                  37.0  0.99660  3.17       0.91   \n",
      "23                    9.0                  67.0  0.99680  3.17       0.53   \n",
      "24                   21.0                  40.0  0.99680  3.43       0.63   \n",
      "25                   11.0                  23.0  0.99550  3.34       0.56   \n",
      "26                    4.0                  11.0  0.99620  3.28       0.59   \n",
      "27                   10.0                  37.0  0.99660  3.17       0.91   \n",
      "28                   14.0                  35.0  0.99720  3.47       0.55   \n",
      "29                    8.0                  16.0  0.99640  3.38       0.59   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "6467                 42.0                 124.0  0.99324  3.31       0.64   \n",
      "6468                  8.0                  81.0  0.99626  3.19       0.51   \n",
      "6469                 29.0                 132.0  0.99188  3.15       0.36   \n",
      "6470                 20.0                  98.0  0.98970  3.37       0.55   \n",
      "6471                 50.0                 179.0  0.99622  3.14       0.60   \n",
      "6472                 33.0                 122.0  0.99044  3.33       0.52   \n",
      "6473                 16.0                 125.0  0.99282  3.49       0.49   \n",
      "6474                 18.0                  97.0  0.99245  3.12       0.41   \n",
      "6475                 34.0                 117.0  0.99132  3.36       0.59   \n",
      "6476                 12.0                  82.0  0.99286  3.25       0.36   \n",
      "6477                  6.0                  81.0  0.99234  3.24       0.35   \n",
      "6478                 68.0                 170.0  0.99494  3.15       0.50   \n",
      "6479                 68.0                 170.0  0.99494  3.15       0.50   \n",
      "6480                 34.0                 118.0  0.99540  3.07       0.50   \n",
      "6481                 45.0                 156.0  0.99184  3.26       0.38   \n",
      "6482                 60.0                 148.0  0.98964  3.27       0.35   \n",
      "6483                 68.0                 174.0  0.99492  3.14       0.50   \n",
      "6484                 68.0                 170.0  0.99494  3.15       0.50   \n",
      "6485                 45.0                 121.0  0.99168  3.21       1.08   \n",
      "6486                  5.0                  56.0  0.98928  3.04       0.79   \n",
      "6487                 38.0                 127.0  0.99330  3.04       0.54   \n",
      "6488                 34.0                 118.0  0.99540  3.07       0.50   \n",
      "6489                 25.0                 100.0  0.98938  3.06       0.44   \n",
      "6490                 38.0                 121.0  0.99074  3.24       0.46   \n",
      "6491                 29.0                 112.0  0.99298  3.29       0.54   \n",
      "6492                 24.0                  92.0  0.99114  3.27       0.50   \n",
      "6493                 57.0                 168.0  0.99490  3.15       0.46   \n",
      "6494                 30.0                 111.0  0.99254  2.99       0.46   \n",
      "6495                 20.0                 110.0  0.98869  3.34       0.38   \n",
      "6496                 22.0                  98.0  0.98941  3.26       0.32   \n",
      "\n",
      "        alcohol  quality  type  \n",
      "0      9.400000        5     1  \n",
      "1      9.800000        5     1  \n",
      "2      9.800000        5     1  \n",
      "3      9.800000        6     1  \n",
      "4      9.400000        5     1  \n",
      "5      9.400000        5     1  \n",
      "6      9.400000        5     1  \n",
      "7     10.000000        7     1  \n",
      "8      9.500000        7     1  \n",
      "9     10.500000        5     1  \n",
      "10     9.200000        5     1  \n",
      "11    10.500000        5     1  \n",
      "12     9.900000        5     1  \n",
      "13     9.100000        5     1  \n",
      "14     9.200000        5     1  \n",
      "15     9.200000        5     1  \n",
      "16    10.500000        7     1  \n",
      "17     9.300000        5     1  \n",
      "18     9.000000        4     1  \n",
      "19     9.200000        6     1  \n",
      "20     9.400000        6     1  \n",
      "21     9.700000        5     1  \n",
      "22     9.500000        5     1  \n",
      "23     9.400000        5     1  \n",
      "24     9.700000        6     1  \n",
      "25     9.300000        5     1  \n",
      "26     9.500000        5     1  \n",
      "27     9.500000        5     1  \n",
      "28     9.400000        5     1  \n",
      "29     9.800000        6     1  \n",
      "...         ...      ...   ...  \n",
      "6467  10.800000        6     0  \n",
      "6468   9.800000        6     0  \n",
      "6469  11.450000        7     0  \n",
      "6470  12.050000        6     0  \n",
      "6471   9.700000        5     0  \n",
      "6472  11.900000        6     0  \n",
      "6473  10.000000        6     0  \n",
      "6474   9.700000        6     0  \n",
      "6475  11.600000        7     0  \n",
      "6476   8.800000        5     0  \n",
      "6477   9.500000        4     0  \n",
      "6478   9.533333        6     0  \n",
      "6479   9.533333        6     0  \n",
      "6480   9.400000        6     0  \n",
      "6481  10.700000        5     0  \n",
      "6482  11.500000        6     0  \n",
      "6483   9.600000        5     0  \n",
      "6484   9.550000        6     0  \n",
      "6485  12.150000        7     0  \n",
      "6486  13.000000        7     0  \n",
      "6487   9.200000        5     0  \n",
      "6488   9.400000        6     0  \n",
      "6489  11.800000        6     0  \n",
      "6490  10.600000        6     0  \n",
      "6491   9.700000        5     0  \n",
      "6492  11.200000        6     0  \n",
      "6493   9.600000        5     0  \n",
      "6494   9.400000        6     0  \n",
      "6495  12.800000        7     0  \n",
      "6496  11.800000        6     0  \n",
      "\n",
      "[6497 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "white = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=';')\n",
    "red = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\", sep=';')\n",
    "red['type'] = 1\n",
    "white['type'] = 0\n",
    "wines = red.append(white, ignore_index=True)\n",
    "print(wines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splitting the training and testing data up..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=wines.ix[:,0:11]\n",
    "\n",
    "import numpy as np\n",
    "# Specify the target labels and flatten the array \n",
    "y=np.ravel(wines.type)\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now preprocessing it (scaling it)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Define the scaler \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Scale the train set\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "# Scale the test set\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to build the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.46768188, -0.20690659,  0.19454014,  0.40433061, -0.12825972,\n",
       "         -0.19746977,  0.48810107,  0.05324084, -0.27453154, -0.3922379 ,\n",
       "         -0.26274365,  0.0986771 ],\n",
       "        [ 0.12212199, -0.15924016, -0.19313344,  0.03545451,  0.34503835,\n",
       "         -0.22031054, -0.20637214, -0.48975328, -0.32197148, -0.3019076 ,\n",
       "         -0.10916969,  0.47060812],\n",
       "        [-0.0455668 , -0.30403182,  0.16538107, -0.31958482, -0.20388624,\n",
       "          0.08870447, -0.32105011, -0.38513157, -0.02984491, -0.23782057,\n",
       "          0.42403799,  0.00846273],\n",
       "        [ 0.23116392,  0.42496592,  0.319875  , -0.18751651, -0.35709694,\n",
       "         -0.40893933,  0.10955435,  0.43737727, -0.27815938,  0.42227936,\n",
       "          0.46731526,  0.40870965],\n",
       "        [-0.38671583, -0.06386104, -0.3281675 , -0.21195871,  0.09687877,\n",
       "          0.19237345,  0.26051933,  0.31912512,  0.39482474,  0.2396217 ,\n",
       "         -0.02934137,  0.48639768],\n",
       "        [-0.28085023, -0.30902195,  0.50599283, -0.23938522, -0.22943696,\n",
       "         -0.17779097, -0.01888862, -0.06339562,  0.02033895,  0.36414933,\n",
       "          0.3429665 ,  0.3326965 ],\n",
       "        [-0.43045959,  0.13755625, -0.0592266 ,  0.2484237 ,  0.30826855,\n",
       "         -0.50195044, -0.17859077, -0.38275638, -0.01065379, -0.21818608,\n",
       "          0.08830482,  0.45788717],\n",
       "        [ 0.28377873,  0.0096252 , -0.50003105, -0.19600374, -0.18446428,\n",
       "         -0.29185888,  0.39858055,  0.37343961,  0.40265995,  0.17068684,\n",
       "         -0.0860166 , -0.30280119],\n",
       "        [ 0.4656629 ,  0.04608303, -0.12631476, -0.32275301, -0.50001925,\n",
       "          0.09264046,  0.09366989,  0.15584522, -0.28581309,  0.34217083,\n",
       "         -0.40138417,  0.46643358],\n",
       "        [-0.33551848, -0.42247322,  0.20904344,  0.47318375,  0.25118977,\n",
       "         -0.44915542, -0.46040994, -0.05316046,  0.25240803, -0.11801639,\n",
       "          0.26537979, -0.20552716],\n",
       "        [-0.22639689,  0.31889266, -0.44558492,  0.48834521,  0.20103478,\n",
       "         -0.12068129, -0.1123313 ,  0.1337707 , -0.33154005, -0.28151   ,\n",
       "          0.35008097,  0.11739987]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[ -3.05133671e-01,  -3.49699974e-01,   2.75745809e-01,\n",
       "          -9.63968933e-02,   3.85200083e-01,   1.93846464e-01,\n",
       "          -1.14805698e-02,   3.60048413e-02],\n",
       "        [ -5.42774916e-01,   9.89347100e-02,   7.71483183e-02,\n",
       "          -4.22142744e-02,  -1.19806349e-01,  -4.88288015e-01,\n",
       "           1.07039988e-01,   1.89682424e-01],\n",
       "        [  4.21126366e-01,   2.08860040e-01,  -1.24782920e-02,\n",
       "          -1.79827213e-04,   2.16225028e-01,  -3.92641366e-01,\n",
       "           4.39404488e-01,   7.72162080e-02],\n",
       "        [ -8.13854933e-02,  -4.19359624e-01,  -1.66452497e-01,\n",
       "          -2.33780921e-01,   3.42226088e-01,   5.31900287e-01,\n",
       "           3.39686513e-01,   3.47867608e-02],\n",
       "        [  3.34836662e-01,  -4.37058777e-01,   4.05164659e-01,\n",
       "          -3.02874267e-01,  -8.29099715e-02,  -2.18544006e-01,\n",
       "          -2.48867035e-01,   3.78189921e-01],\n",
       "        [ -4.75028843e-01,  -2.02107906e-01,   2.37195015e-01,\n",
       "          -1.14505947e-01,   4.66660976e-01,  -5.09344578e-01,\n",
       "          -1.93178624e-01,  -1.85872644e-01],\n",
       "        [  2.43812621e-01,   3.18666577e-01,  -1.34324372e-01,\n",
       "           4.86377478e-01,   1.92196608e-01,   7.08937049e-02,\n",
       "          -3.13080966e-01,  -2.05460727e-01],\n",
       "        [  2.70081043e-01,   1.90519989e-01,   5.00686407e-01,\n",
       "          -2.15694904e-02,  -5.43598890e-01,   2.75987625e-01,\n",
       "           1.35905921e-01,  -4.60464299e-01],\n",
       "        [ -2.30415970e-01,   1.82577550e-01,   1.59734070e-01,\n",
       "          -3.67967546e-01,  -1.72874272e-01,  -2.97027588e-01,\n",
       "           2.46518910e-01,   2.91656792e-01],\n",
       "        [  2.14852452e-01,  -2.28667527e-01,   3.96544337e-01,\n",
       "          -1.79388225e-01,  -2.35503644e-01,   1.10445857e-01,\n",
       "          -4.38428521e-02,  -8.51012170e-02],\n",
       "        [ -3.85921597e-01,   3.94600570e-01,  -4.08344209e-01,\n",
       "          -1.07198417e-01,  -5.11711180e-01,   2.18513429e-01,\n",
       "           1.19170368e-01,   3.50685775e-01],\n",
       "        [ -5.10849357e-02,   5.01353621e-01,   3.15998793e-02,\n",
       "          -4.99533921e-01,   2.88238287e-01,  -3.85723472e-01,\n",
       "           3.88831735e-01,  -4.28767264e-01]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[-0.61974728],\n",
       "        [ 0.12266338],\n",
       "        [ 0.51932979],\n",
       "        [-0.7393384 ],\n",
       "        [ 0.49997687],\n",
       "        [ 0.62142181],\n",
       "        [ 0.18188429],\n",
       "        [ 0.74289131]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(12, activation='relu', input_shape=(11,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to compile the model and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4352/4352 [==============================] - 8s 2ms/step - loss: 0.1064 - acc: 0.9582\n",
      "Epoch 2/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0224 - acc: 0.9963\n",
      "Epoch 3/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0204 - acc: 0.9963\n",
      "Epoch 4/20\n",
      "4352/4352 [==============================] - 10s 2ms/step - loss: 0.0177 - acc: 0.9968\n",
      "Epoch 5/20\n",
      "4352/4352 [==============================] - 9s 2ms/step - loss: 0.0164 - acc: 0.9970\n",
      "Epoch 6/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0141 - acc: 0.9972\n",
      "Epoch 7/20\n",
      "4352/4352 [==============================] - 6s 1ms/step - loss: 0.0133 - acc: 0.9975\n",
      "Epoch 8/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0144 - acc: 0.9972\n",
      "Epoch 9/20\n",
      "4352/4352 [==============================] - 8s 2ms/step - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 10/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0121 - acc: 0.9970\n",
      "Epoch 11/20\n",
      "4352/4352 [==============================] - 8s 2ms/step - loss: 0.0104 - acc: 0.9975\n",
      "Epoch 12/20\n",
      "4352/4352 [==============================] - 8s 2ms/step - loss: 0.0139 - acc: 0.9970\n",
      "Epoch 13/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 14/20\n",
      "4352/4352 [==============================] - 6s 1ms/step - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 15/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0104 - acc: 0.9977\n",
      "Epoch 16/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0090 - acc: 0.9975\n",
      "Epoch 17/20\n",
      "4352/4352 [==============================] - 7s 2ms/step - loss: 0.0088 - acc: 0.9984\n",
      "Epoch 18/20\n",
      "4352/4352 [==============================] - 6s 1ms/step - loss: 0.0084 - acc: 0.9984\n",
      "Epoch 19/20\n",
      "4352/4352 [==============================] - 6s 1ms/step - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 20/20\n",
      "4352/4352 [==============================] - 6s 1ms/step - loss: 0.0079 - acc: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd634c91630>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(X_train, y_train,epochs=20, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been trained!  Thanks, Google.  Now to see the predictions the network made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145/2145 [==============================] - 0s 33us/step\n",
      "[0.022433815116655837, 0.99533799533799538]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "score = model.evaluate(X_test, y_test,verbose=1)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
